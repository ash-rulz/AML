---
title: "Lab2GroupReport"
author: "aswma317, akssr921,varsi146"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(HMM)
library(entropy)
```

## Question 1

```{r , echo=TRUE, eval=TRUE}
####1: Build a HMM####
num_states <- 10#There are 10 possible States(unobserved)
num_symbols <- 10#There are 5 possible Symbols, but 10 states(observed)

#Uniform initial probability for each state
initial_probs <- rep(1/num_states, num_states)

#Transition probabilities(Unobserved states to unobserved states)
transition_probs <- matrix(0, num_states, num_states)
for (i in 1:num_states) {
  #It has 2 choices: move right or stay. Cannot move backward
  transition_probs[i,i] <- 1/2

  right <- ifelse(i+1 == 11, 1, i+1)#Considers circular reference
  transition_probs[i,right] <- 1/2
}
transition_probs

#Emission probabilities(Unobserved states to observed symbols)
emission_probs <- matrix(
  c(0.2,0.2,0.2,0,0,0,0,0,0.2,0.2,
    0.2,0.2,0.2,0.2,0,0,0,0,0,0.2,
    0.2,0.2,0.2,0.2,0.2,0,0,0,0,0,
    0,0.2,0.2,0.2,0.2,0.2,0,0,0,0,
    0,0,0.2,0.2,0.2,0.2,0.2,0,0,0,
    0,0,0,0.2,0.2,0.2,0.2,0.2,0,0,
    0,0,0,0,0.2,0.2,0.2,0.2,0.2,0,
    0,0,0,0,0,0.2,0.2,0.2,0.2,0.2,
    0.2,0,0,0,0,0,0.2,0.2,0.2,0.2,
    0.2,0.2,0,0,0,0,0,0.2,0.2,0.2), num_states, num_states)
emission_probs

# Create the HMM
hmm_model <- initHMM(States = as.character(1:num_states), Symbols = as.character(1:num_symbols),
                     startProbs = initial_probs,
                     transProbs = transition_probs,
                     emissionProbs = emission_probs)

print(hmm_model)
```

## Question 2

```{r , echo=TRUE, eval=TRUE}
####2: Simulate HMM for 100 steps####
# Simulate the HMM for 100 time steps
run_simulation <- function(num_steps, hmm_model){
  #set.seed(123)
  simulated_data <- simHMM(hmm_model, length = num_steps)

# All the observations are within [i - 2, i + 2] distance
  return(simulated_data)
}
num_steps <- 100 #Time steps
simulated_data <- run_simulation(num_steps, hmm_model)

# Extract the sequence of states and observations
states_sequence <- simulated_data$states
observations_sequence <- simulated_data$observation

#Print the sequences (states and observations)
print("States Sequence:")
states_sequence
print("Observations Sequence:")
observations_sequence
```

## Question 3

Below is the code for the filtered and smoothed probability distributions for each of the 100 time point and also to compute the most probable path.

```{r , echo=FALSE, eval=TRUE}

```

```{r , echo=TRUE, eval=TRUE}
sample = simHMM(hmm_model,100)
fil_smooth <- function(sam){
  observed <- sam$observation
    #calculate alpha
  alpha <-  exp(forward(hmm_model, observed))
    #filtering
  fil <-  apply(alpha,2,prop.table)
    #calculating beta
  beta <-  exp(backward(hmm_model,observed))

    #smoothing
  smo <-  alpha*beta
  smooth <- apply(smo,2,prop.table)
  return(list(fil,smooth))
}


#filtering
filter <-  fil_smooth(sample)[[1]]

smooth <- fil_smooth(sample)[[2]]

#path of viterbi algorithm
path = viterbi(hmm_model, sample$observation)


cat('The most Probable Path is')
path
```

Filtered and smoothed  probability distribution values can be seen below
```{r , echo=TRUE, eval=TRUE}
filter[,1:10]
smooth[,1:10]

```

## Question 4

```{r , echo=TRUE, eval=TRUE}
#function to return the states name from probability table
fil_smooth_pred <- function(x){
  sta <- rep(NA,ncol(x))
  for(i in 1:ncol(x)){
    sta[i] <- names(which.max(x[,i]))
  }
  return(sta)
}

#getting the predicted states
filter_pred <- fil_smooth_pred(filter)
smooth_pred <- fil_smooth_pred(smooth)


#function to calculate accuracy
cal_accuracy <- function(pre,act){
  t <- table(pre,act)
  acc <- sum(diag(t))/ sum(t)
  return(acc)
}

#accuracy of filtering
acc_filter <- cal_accuracy(filter_pred,sample$states)

#accuracy of smoothing
acc_smooth <- cal_accuracy(smooth_pred,sample$states)

#viterbi accuracy
acc_viterbi <- cal_accuracy(path,sample$states)

cat('Accuracy of filtered probability distributions is',acc_filter*100,'%')

cat('Accuracy of smoothed probability distributions is',acc_smooth*100,'%')

cat('Accuracy of most probable path is',acc_viterbi*100,'%')
```

## Question 5

```{r , echo=FALSE, eval=TRUE}
# CODE REPEATED
num_states <- 10
hidden_states <- paste0('S', 1:num_states)
obs_states <- paste0('s', 1:num_states)

init_prob <- runif(10, min = 0, max = 1)

# Defining the transition matrix dimension: hidden_states x hidden_states

transMat <- matrix(0, nrow = num_states, ncol = num_states)
rownames(transMat) <- hidden_states
colnames(transMat) <- hidden_states

for (i in 1:num_states) {
  transMat[i, i] <- 0.5  # Probability of staying in the current sector
  if (i < num_states) {
    transMat[i, i + 1] <- 0.5  # Probability of moving to the next sector
  }else{
    transMat[i, 1] <- 0.5
  }
}

# Defining emission matrix with dimension: hidden_states x obs_symbols
emissMat <- matrix(c(0.2,0.2,0.2,0,0,0,0,0,0.2,0.2,
    0.2,0.2,0.2,0.2,0,0,0,0,0,0.2,
    0.2,0.2,0.2,0.2,0.2,0,0,0,0,0,
    0,0.2,0.2,0.2,0.2,0.2,0,0,0,0,
    0,0,0.2,0.2,0.2,0.2,0.2,0,0,0,
    0,0,0,0.2,0.2,0.2,0.2,0.2,0,0,
    0,0,0,0,0.2,0.2,0.2,0.2,0.2,0,
    0,0,0,0,0,0.2,0.2,0.2,0.2,0.2,
    0.2,0,0,0,0,0,0.2,0.2,0.2,0.2,
    0.2,0.2,0,0,0,0,0,0.2,0.2,0.2),nrow = 10,byrow = TRUE)
rownames(emissMat) <- obs_states
colnames(emissMat) <- obs_states


hmm_model1 <- initHMM(States=hidden_states, 
                     Symbols=obs_states, 
                     startProbs=init_prob, 
                     transProbs=transMat, emissionProbs=emissMat)
# CODE REPEATED
```

```{r , echo=TRUE, eval=TRUE}
simulate_HMM <- function(model, time_steps, alt_method = FALSE){
  sim_timeStep <- simHMM(model, length = time_steps)
  sim_actual <- sim_timeStep$states
  sim_obs <- sim_timeStep$observation

  Alpha <- exp(forward(hmm = model, observation = sim_obs))
  Beta <- exp(backward(hmm = model, observation = sim_obs))

  filtered <- apply(Alpha,2,prop.table)
  filter_pred <- apply(filtered, 2, which.max)
  filter_pred <- sapply(filter_pred, function(x) paste0('s',x))

  if (alt_method == FALSE) {
    smoothed <- Alpha*Beta
    smoothed <- apply(smoothed, 2, prop.table)
    smoothed_pred <- apply(smoothed, 2, which.max)
    smoothed_pred <- sapply(smoothed_pred, function(x) paste0('s',x))
  }else{
    # Alternative method to calculate smoothed distribution. Correct?
    smoothed <- posterior(hmm = model, observation = sim_obs)
    smoothed_pred <- apply(smoothed, 2, which.max)
    smoothed_pred <- sapply(smoothed_pred, function(x) paste0('s',x))
  }


  viterbi_path <- viterbi(hmm = model, observation = sim_obs)

  return(list('actual' = sim_actual, 'obs' = sim_obs,'filter_pred'= filter_pred,
              'smoothed_pred' = smoothed_pred,
              'viterbi' = viterbi_path, 'filter_mat' = filtered))
}

accuracy <- function(actual, pred){
  accuracy <- sum(diag(table(actual, pred)))/sum(table(actual, pred))
  return(accuracy)
}

sim100_results <- simulate_HMM(model = hmm_model1, time_steps = 100, alt_method = FALSE)

sim100_samplesRes <- list(
  filter_accs = NULL,
  smooth_accs = NULL,
  viterbi_accs = NULL
)

for (i in 1:100) {
  simulate_hmm_vals <- simulate_HMM(model = hmm_model1, time_steps = 100, alt_method = FALSE)
  sim100_samplesRes$filter_accs[i] <- accuracy(actual = simulate_hmm_vals$actual, 
                                               pred = simulate_hmm_vals$filter_pred)
  
  sim100_samplesRes$smooth_accs[i] <- accuracy(actual = simulate_hmm_vals$actual, 
                                               pred = simulate_hmm_vals$smoothed_pred)
  
  sim100_samplesRes$viterbi_accs[i] <- accuracy(actual = simulate_hmm_vals$actual, 
                                               pred = simulate_hmm_vals$viterbi)
}


cat('The mean accuracy of filtered distribution is', mean(sim100_samplesRes$filter_accs), '\n')
cat('The mean accuracy of smoothed distribution is', mean(sim100_samplesRes$smooth_accs), '\n')
cat('The mean accuracy of most probable paths distribution is', mean(sim100_samplesRes$viterbi_accs), '\n')


plot(sim100_samplesRes$filter_accs, type = 'l', 
     col = 'red', ylim = c(0.2, 1.2), ylab = 'Accuracy')
lines(sim100_samplesRes$smooth_accs, type = 'l', col = 'blue')
lines(sim100_samplesRes$viterbi_accs, type = 'l', col = 'green')
# Adding Legend
legend("topright", legend = c("Filtered Distribution Accuracies", "Smoothed distribution Accuracies", "Viterbi Accuracies"),
       col = c("red", "blue", "green"), lty = 1)
```

From the results above, we can see that in general, smoothed distributions are more accurate compared to filtered distributions, and this can be represented mathematically as well.

Smoothing is given by the following expression: $p(z^t|x^{0:T})$

While, filtering is given by the following expression: $p(z^t|x^{0:t})$

$T$ in the smoothing expression means that the entire process has finished running and we calculate the probability of the hidden states given all the observations from start to the end of the process. While, the expression for filtering has $t$ implying that the probability of hidden states are calculated only using the observations upto time step $t$ and is hence more sensitive to short-term fluctuations or noisy data. In general, smoothed distributions are more accurate because they consider a broader context and hence are less sensitive to short-term fluctuations.

The Viterbi algorithm aims to find the single most probable sequence of states, by trying to maximize the joint probability of the observations and the states i.e., $p(x_1,....,x_t,z_1,....,z_t)$. It behaves the same way as the Smoothed distribution, in the sense that it accounts for the entire data while calculating the probability of the hidden state. However, the drawback and constraint with Viterbi algorithm is that it makes sure that the states in the probable path are continuous(no jumps) regardless of the probability distribution, while in the Smoothed distribution, we may find jumps from one state to non-neighboring states, because this states may be more probable. Because of this drawback and the noisy data, the probable path obtained from Viterbi algorithm is having lesser accuracy than the Smoothed distribution.

## Question 6

In general, one would expect that later in time, as the number of observations increase we know better about the robot's position.

To do so, we are checking the entropy of the filtered distribution. However, since we have faulty/noisy observations(recall that there is only 20% probability that a given observation is correct) there is bound to be considerable amount of uncertainty even as the number of observations increase.

```{r , echo=TRUE, eval=TRUE, out.width='75%'}
entropies <- c()
new_simHMM <- simHMM(hmm = hmm_model1, length = 300)
new_obs <- new_simHMM$observation
Alpha_new <- exp(forward(hmm = hmm_model1, observation = new_obs))
filtered <- apply(Alpha_new,2,prop.table)
for (i in seq(30, 300, 5)) {
  
  entropies <- c(entropies, entropy.empirical(filtered[,i]))
}

plot(seq(30, 300, 5),entropies, 
     type = 'l', xlab = 'Time Steps', ylab = 'Entropy')
```

## Question 7

To compute the probability of hidden states for time step 101 given time step 100, we can write it as:

$$
p(z^{T+1}|x^{1:T}) = \sum_{z^{T}} p(z^{T+1}, z^{T}|x^{1:T})
$$
that is,

$$
p(z^{101}|x^{1:100}) = \sum_{z^{100}} p(z^{101}, z^{100}|x^{1:100})
$$
$$
= \sum_{z^{100}} p(z^{100}|x^{1:100})\cdot p(z^{101}|z^{100})
$$

That is, the probability distribution of the hidden state at time step 101 is given by the product of the 100th time step of the filtered distribution and the transition matrix.

```{r , echo=TRUE, eval=TRUE}
print('The probabilities of the hidden states of time step 101 given time step 100 is:')
transMat %*% sim100_results$filter_mat[,100]
```

## Contribution:

All the 3 members worked on all the questions, and then the solutions were compared. All 3 members collaborated in documenting the report. For Q1-2, Aswath's solution was used, for Q3-4 Akshath's solution was used, for Q5-7 Varun's solution was used. In addition, for Q6-7, we reasoned the solution as a group.